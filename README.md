# SahraEvent RAG Demo

A fast, reliable RAG system for event venue recommendations using Streamlit and LangGraph.

![](pictures/interface.png)
![](pictures/log.png)

## Quick Start

### Prerequisites
- Python 3.8+
- OpenAI API key

### Setup
1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Set your API key:**
   ```bash
   export OPENAI_API_KEY="your_api_key_here"
   ```

3. **Run the app:**
   ```bash
   streamlit run app.py
   ```

The app will be available at `http://localhost:8501`

## Project Structure
- `app.py` â€“ Streamlit UI
- `rag/` â€“ Core RAG pipeline
  - `graph.py` â€“ LangGraph orchestration
  - `retriever.py` â€“ Hybrid search with deduplication
  - `store.py` â€“ Dual-index storage
  - `prompts.py` â€“ System prompts
  - `config.py` â€“ Configuration settings
  - `cache.py` â€“ TTL caching
  - `utils.py` â€“ Helper functions
- `data/` â€“ Sample venue datasets
  - `vendors.csv` â€“ Basic dataset

## Usage
Ask natural language questions like:
- "yacht party in Dubai for 25 people"
- "luxury wedding venue in Abu Dhabi under 50k"
- "beach club for corporate event"


## Summary: What's Ready vs What's Next

### âœ… **Production-Ready (MVP)**
- âœ… Core RAG pipeline with LangGraph orchestration
- âœ… BM25 hybrid search with metadata filters
- âœ… Vendor deduplication for result diversity
- âœ… Dual-index architecture (stable/hot)
- âœ… Staleness detection and display
- âœ… TTL-based caching
- âœ… Citation-enforced responses
- âœ… Model routing (cost-optimized)

### ðŸŸ¡ **Partially Implemented / MVP Mode**
- ðŸŸ¡ SQLite instead of Postgres (scalable to ~10K venues)
- ðŸŸ¡ In-memory cache instead of Redis (single instance only)
- ðŸŸ¡ Streamlit UI instead of FastAPI (demo/internal use)
- ðŸŸ¡ Reranker ready but not active

### âŒ **Not Yet Implemented**
- âŒ FastAPI REST endpoints
- âŒ WhatsApp/Stripe/Calendar integrations
- âŒ Real-time vendor availability checks
- âŒ Webhook-based ingestion
- âŒ Precomputed warm paths for seasonal queries
- âŒ Int8 quantized embeddings

### ðŸŽ¯ **Next Steps for Production**
1. **Scale Storage**: Migrate to Postgres + pgvector when dataset >10K
2. **Enable Dense Search**: Fix segfault issues, re-enable FAISS
3. **Add Redis**: For multi-instance deployment
4. **FastAPI**: Expose REST endpoints for integrations
5. **External Tools**: Vendor availability API, calendar checks
6. **Webhooks**: Real-time vendor updates

---

## Technical Details
- **Storage**: SQLite database with dual-index architecture (stable/hot)
- **Search**: BM25-only mode (FAISS embeddings disabled for stability)
- **Pipeline**: LangGraph orchestration with async nodes
- **Validation**: Automatic detection of missing slots and stale data
- **Citations**: Proper venue ID references for traceability
- **Caching**: TTL-based caching for queries (6h) and completions (24h)
- **Deduplication**: Vendor-level filtering to ensure diverse results

## Performance Characteristics
- **Latency**: ~2-5s per query (mostly LLM API time)
- **Cache Hit Rate**: 60-80% for common queries
- **Throughput**: Suitable for <100 concurrent users (Streamlit limitation)
- **Cost**: ~$0.002-0.005 per query (gpt-4o-mini)

## Configuration
Edit `rag/config.py` to adjust:
- `keep_top_n`: Initial retrieval count (default: 15)
- `context_top_n`: Documents sent to LLM (default: 3)
- `tool_timeout_s`: LLM API timeout (default: 30s)
- `small_model` / `mid_model` / `large_model`: Model selection

## License
MIT
